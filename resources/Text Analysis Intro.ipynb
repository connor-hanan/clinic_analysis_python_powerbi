{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7493483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing TextBlob\n",
    "from textblob import TextBlob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14bcda11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence \n",
    "\n",
    "sentence = \"Hi, I am a happy data scientist.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4e508eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"Hi, I am a happy data scientist.\")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# intitializing our text blob\n",
    "blob =  TextBlob(sentence)\n",
    "blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0701405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['Hi', ',', 'I', 'am', 'a', 'happy', 'data', 'scientist', '.'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize our blob\n",
    "words = blob.tokenize()\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c7cc9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a stop word list\n",
    "stop_words = [',','I', 'a','am','.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5f9c4ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi', 'happy', 'data', 'scientist']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_tokens = [w for w in words if w not in stop_words]\n",
    "clean_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9242ccc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi happy data scientist'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_sentence =\" \".join(clean_tokens)\n",
    "clean_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f066d2c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"Hi happy data scientist\")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a new text blob\n",
    "clean_blob  = TextBlob(clean_sentence)\n",
    "clean_blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "848beaed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Hi', 'NNP'), ('happy', 'JJ'), ('data', 'NNS'), ('scientist', 'NN')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_blob.tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dbd1f102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at ngrams \n",
    "\n",
    "blob3  =  TextBlob('I like Brad Pitt enormously. He is an actor with brains and wit, not to mention face, pectorals and all the rest. Since I saw him in \"Thelma and Louise\" a thought has been bothering me, who does he remind me of? \"Troy\" did it for me. He is the new Brigitte Bardot. The differences are obvious of course. Male, American etc but Brigitte Bardot comes to mind nonetheless. He is so beautiful that he is at his most effective when he plays against it. \"Kalifornia\" \"12 Monkeys\" \"Fight Club\" \"Snatch\" His self deprecating humor makes him human, almost accessible. Fortunately \"Troy\" will soon be forgotten. Only still photographs with Pitt, semi naked in ravishing sprint positions will decorate the walls of legions of salivating fans. Strange, \"Das Boot\" is one of the great films of the second part of the 20th Century. What is Wolfgang Petersen doing directing this? Well, I suppose it would be very hard to say no at the chance of working with the new Brigitte Bardot.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40ca7d93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WordList(['I', 'like']),\n",
       " WordList(['like', 'Brad']),\n",
       " WordList(['Brad', 'Pitt']),\n",
       " WordList(['Pitt', 'enormously']),\n",
       " WordList(['enormously', 'He']),\n",
       " WordList(['He', 'is']),\n",
       " WordList(['is', 'an']),\n",
       " WordList(['an', 'actor']),\n",
       " WordList(['actor', 'with']),\n",
       " WordList(['with', 'brains']),\n",
       " WordList(['brains', 'and']),\n",
       " WordList(['and', 'wit']),\n",
       " WordList(['wit', 'not']),\n",
       " WordList(['not', 'to']),\n",
       " WordList(['to', 'mention']),\n",
       " WordList(['mention', 'face']),\n",
       " WordList(['face', 'pectorals']),\n",
       " WordList(['pectorals', 'and']),\n",
       " WordList(['and', 'all']),\n",
       " WordList(['all', 'the']),\n",
       " WordList(['the', 'rest']),\n",
       " WordList(['rest', 'Since']),\n",
       " WordList(['Since', 'I']),\n",
       " WordList(['I', 'saw']),\n",
       " WordList(['saw', 'him']),\n",
       " WordList(['him', 'in']),\n",
       " WordList(['in', 'Thelma']),\n",
       " WordList(['Thelma', 'and']),\n",
       " WordList(['and', 'Louise']),\n",
       " WordList(['Louise', 'a']),\n",
       " WordList(['a', 'thought']),\n",
       " WordList(['thought', 'has']),\n",
       " WordList(['has', 'been']),\n",
       " WordList(['been', 'bothering']),\n",
       " WordList(['bothering', 'me']),\n",
       " WordList(['me', 'who']),\n",
       " WordList(['who', 'does']),\n",
       " WordList(['does', 'he']),\n",
       " WordList(['he', 'remind']),\n",
       " WordList(['remind', 'me']),\n",
       " WordList(['me', 'of']),\n",
       " WordList(['of', 'Troy']),\n",
       " WordList(['Troy', 'did']),\n",
       " WordList(['did', 'it']),\n",
       " WordList(['it', 'for']),\n",
       " WordList(['for', 'me']),\n",
       " WordList(['me', 'He']),\n",
       " WordList(['He', 'is']),\n",
       " WordList(['is', 'the']),\n",
       " WordList(['the', 'new']),\n",
       " WordList(['new', 'Brigitte']),\n",
       " WordList(['Brigitte', 'Bardot']),\n",
       " WordList(['Bardot', 'The']),\n",
       " WordList(['The', 'differences']),\n",
       " WordList(['differences', 'are']),\n",
       " WordList(['are', 'obvious']),\n",
       " WordList(['obvious', 'of']),\n",
       " WordList(['of', 'course']),\n",
       " WordList(['course', 'Male']),\n",
       " WordList(['Male', 'American']),\n",
       " WordList(['American', 'etc']),\n",
       " WordList(['etc', 'but']),\n",
       " WordList(['but', 'Brigitte']),\n",
       " WordList(['Brigitte', 'Bardot']),\n",
       " WordList(['Bardot', 'comes']),\n",
       " WordList(['comes', 'to']),\n",
       " WordList(['to', 'mind']),\n",
       " WordList(['mind', 'nonetheless']),\n",
       " WordList(['nonetheless', 'He']),\n",
       " WordList(['He', 'is']),\n",
       " WordList(['is', 'so']),\n",
       " WordList(['so', 'beautiful']),\n",
       " WordList(['beautiful', 'that']),\n",
       " WordList(['that', 'he']),\n",
       " WordList(['he', 'is']),\n",
       " WordList(['is', 'at']),\n",
       " WordList(['at', 'his']),\n",
       " WordList(['his', 'most']),\n",
       " WordList(['most', 'effective']),\n",
       " WordList(['effective', 'when']),\n",
       " WordList(['when', 'he']),\n",
       " WordList(['he', 'plays']),\n",
       " WordList(['plays', 'against']),\n",
       " WordList(['against', 'it']),\n",
       " WordList(['it', 'Kalifornia']),\n",
       " WordList(['Kalifornia', '12']),\n",
       " WordList(['12', 'Monkeys']),\n",
       " WordList(['Monkeys', 'Fight']),\n",
       " WordList(['Fight', 'Club']),\n",
       " WordList(['Club', 'Snatch']),\n",
       " WordList(['Snatch', 'His']),\n",
       " WordList(['His', 'self']),\n",
       " WordList(['self', 'deprecating']),\n",
       " WordList(['deprecating', 'humor']),\n",
       " WordList(['humor', 'makes']),\n",
       " WordList(['makes', 'him']),\n",
       " WordList(['him', 'human']),\n",
       " WordList(['human', 'almost']),\n",
       " WordList(['almost', 'accessible']),\n",
       " WordList(['accessible', 'Fortunately']),\n",
       " WordList(['Fortunately', 'Troy']),\n",
       " WordList(['Troy', 'will']),\n",
       " WordList(['will', 'soon']),\n",
       " WordList(['soon', 'be']),\n",
       " WordList(['be', 'forgotten']),\n",
       " WordList(['forgotten', 'Only']),\n",
       " WordList(['Only', 'still']),\n",
       " WordList(['still', 'photographs']),\n",
       " WordList(['photographs', 'with']),\n",
       " WordList(['with', 'Pitt']),\n",
       " WordList(['Pitt', 'semi']),\n",
       " WordList(['semi', 'naked']),\n",
       " WordList(['naked', 'in']),\n",
       " WordList(['in', 'ravishing']),\n",
       " WordList(['ravishing', 'sprint']),\n",
       " WordList(['sprint', 'positions']),\n",
       " WordList(['positions', 'will']),\n",
       " WordList(['will', 'decorate']),\n",
       " WordList(['decorate', 'the']),\n",
       " WordList(['the', 'walls']),\n",
       " WordList(['walls', 'of']),\n",
       " WordList(['of', 'legions']),\n",
       " WordList(['legions', 'of']),\n",
       " WordList(['of', 'salivating']),\n",
       " WordList(['salivating', 'fans']),\n",
       " WordList(['fans', 'Strange']),\n",
       " WordList(['Strange', 'Das']),\n",
       " WordList(['Das', 'Boot']),\n",
       " WordList(['Boot', 'is']),\n",
       " WordList(['is', 'one']),\n",
       " WordList(['one', 'of']),\n",
       " WordList(['of', 'the']),\n",
       " WordList(['the', 'great']),\n",
       " WordList(['great', 'films']),\n",
       " WordList(['films', 'of']),\n",
       " WordList(['of', 'the']),\n",
       " WordList(['the', 'second']),\n",
       " WordList(['second', 'part']),\n",
       " WordList(['part', 'of']),\n",
       " WordList(['of', 'the']),\n",
       " WordList(['the', '20th']),\n",
       " WordList(['20th', 'Century']),\n",
       " WordList(['Century', 'What']),\n",
       " WordList(['What', 'is']),\n",
       " WordList(['is', 'Wolfgang']),\n",
       " WordList(['Wolfgang', 'Petersen']),\n",
       " WordList(['Petersen', 'doing']),\n",
       " WordList(['doing', 'directing']),\n",
       " WordList(['directing', 'this']),\n",
       " WordList(['this', 'Well']),\n",
       " WordList(['Well', 'I']),\n",
       " WordList(['I', 'suppose']),\n",
       " WordList(['suppose', 'it']),\n",
       " WordList(['it', 'would']),\n",
       " WordList(['would', 'be']),\n",
       " WordList(['be', 'very']),\n",
       " WordList(['very', 'hard']),\n",
       " WordList(['hard', 'to']),\n",
       " WordList(['to', 'say']),\n",
       " WordList(['say', 'no']),\n",
       " WordList(['no', 'at']),\n",
       " WordList(['at', 'the']),\n",
       " WordList(['the', 'chance']),\n",
       " WordList(['chance', 'of']),\n",
       " WordList(['of', 'working']),\n",
       " WordList(['working', 'with']),\n",
       " WordList(['with', 'the']),\n",
       " WordList(['the', 'new']),\n",
       " WordList(['new', 'Brigitte']),\n",
       " WordList(['Brigitte', 'Bardot'])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob3.ngrams(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abafaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use lemmatization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76373f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "30e79e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'running'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = Word('running')\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d513bf42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'run'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.lemmatize('v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adee8cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8768590d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76418d00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
